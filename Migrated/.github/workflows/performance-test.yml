name: "Performance - Load & Stress Testing"

on:
  push:
    branches: [ main, develop ]
    paths-ignore:
      - '**.md'
      - 'docs/**'
  pull_request:
    branches: [ main, develop ]
    paths-ignore:
      - '**.md'
      - 'docs/**'
  schedule:
    # Run performance tests nightly at 3 AM UTC
    - cron: '0 3 * * *'
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of performance test'
        required: false
        default: 'load'
        type: choice
        options:
          - load
          - stress
          - spike
          - volume
          - endurance
      test_duration:
        description: 'Test duration (in minutes)'
        required: false
        default: '5'
        type: string
      concurrent_users:
        description: 'Number of concurrent users'
        required: false
        default: '100'
        type: string
      target_environment:
        description: 'Target environment'
        required: false
        default: 'staging'
        type: choice
        options:
          - staging
          - development

env:
  DOTNET_VERSION: '8.0.100'
  K6_VERSION: '0.47.0'
  ARTILLERY_VERSION: 'latest'

jobs:
  # Job 1: Performance Test Preparation
  prepare-tests:
    name: "Prepare Performance Tests"
    runs-on: ubuntu-latest
    timeout-minutes: 10

    outputs:
      test-config: ${{ steps.config.outputs.config }}
      target-urls: ${{ steps.urls.outputs.urls }}
      test-suite: ${{ steps.suite.outputs.suite }}

    steps:
    - name: "üì• Checkout Code"
      uses: actions/checkout@v4

    - name: "‚öôÔ∏è Configure Test Parameters"
      id: config
      run: |
        # Set test configuration based on inputs or defaults
        TEST_TYPE="${{ inputs.test_type || 'load' }}"
        DURATION="${{ inputs.test_duration || '5' }}"
        USERS="${{ inputs.concurrent_users || '100' }}"
        ENVIRONMENT="${{ inputs.target_environment || 'staging' }}"
        
        CONFIG="{
          \"type\": \"${TEST_TYPE}\",
          \"duration\": \"${DURATION}m\",
          \"users\": ${USERS},
          \"environment\": \"${ENVIRONMENT}\",
          \"thresholds\": {
            \"http_req_duration\": [\"p(95)<2000\"],
            \"http_req_failed\": [\"rate<0.05\"],
            \"http_reqs\": [\"rate>10\"]
          }
        }"
        
        echo "config=${CONFIG}" >> $GITHUB_OUTPUT
        echo "Test configuration: ${CONFIG}"

    - name: "üåç Set Target URLs"
      id: urls
      run: |
        ENVIRONMENT="${{ inputs.target_environment || 'staging' }}"
        
        if [ "${ENVIRONMENT}" == "staging" ]; then
          URLS="{
            \"api\": \"https://staging-api.credittransfer.com\",
            \"wcf\": \"https://staging-wcf.credittransfer.com\",
            \"web\": \"https://staging.credittransfer.com\"
          }"
        else
          URLS="{
            \"api\": \"http://localhost:5000\",
            \"wcf\": \"http://localhost:5001\",
            \"web\": \"http://localhost:5002\"
          }"
        fi
        
        echo "urls=${URLS}" >> $GITHUB_OUTPUT
        echo "Target URLs: ${URLS}"

    - name: "üìã Generate Test Suite"
      id: suite
      run: |
        SUITE="[
          {\"name\": \"api-health\", \"method\": \"GET\", \"path\": \"/health\", \"service\": \"api\"},
          {\"name\": \"api-denomination\", \"method\": \"GET\", \"path\": \"/api/CreditTransfer/GetDenomination\", \"service\": \"api\"},
          {\"name\": \"wcf-health\", \"method\": \"GET\", \"path\": \"/health\", \"service\": \"wcf\"},
          {\"name\": \"web-health\", \"method\": \"GET\", \"path\": \"/health\", \"service\": \"web\"},
          {\"name\": \"web-home\", \"method\": \"GET\", \"path\": \"/\", \"service\": \"web\"}
        ]"
        
        echo "suite=${SUITE}" >> $GITHUB_OUTPUT

  # Job 2: K6 Load Testing
  k6-load-tests:
    name: "K6 Load Testing"
    runs-on: ubuntu-latest
    needs: prepare-tests
    timeout-minutes: 30

    strategy:
      matrix:
        service: [api, wcf, web]

    steps:
    - name: "üì• Checkout Code"
      uses: actions/checkout@v4

    - name: "üîß Setup K6"
      run: |
        sudo gpg -k
        sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
        echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
        sudo apt-get update
        sudo apt-get install k6

    - name: "üìù Generate K6 Test Script"
      run: |
        CONFIG='${{ needs.prepare-tests.outputs.test-config }}'
        URLS='${{ needs.prepare-tests.outputs.target-urls }}'
        
        # Extract values using jq
        DURATION=$(echo $CONFIG | jq -r '.duration')
        USERS=$(echo $CONFIG | jq -r '.users')
        BASE_URL=$(echo $URLS | jq -r '.${{ matrix.service }}')
        
        cat > k6-test-${{ matrix.service }}.js << EOF
        import http from 'k6/http';
        import { check, sleep } from 'k6';
        import { Rate } from 'k6/metrics';

        export let errorRate = new Rate('errors');

        export let options = {
          stages: [
            { duration: '2m', target: Math.floor($USERS * 0.1) }, // Ramp up
            { duration: '$DURATION', target: $USERS }, // Stay at load
            { duration: '2m', target: 0 }, // Ramp down
          ],
          thresholds: {
            http_req_duration: ['p(95)<2000'], // 95% of requests under 2s
            http_req_failed: ['rate<0.05'], // Error rate under 5%
            errors: ['rate<0.1'], // Custom error rate
          },
        };

        const BASE_URL = '$BASE_URL';

        export default function() {
          // Health check endpoint
          let healthRes = http.get(\`\${BASE_URL}/health\`);
          check(healthRes, {
            'health check status is 200': (r) => r.status === 200,
            'health check response time < 500ms': (r) => r.timings.duration < 500,
          }) || errorRate.add(1);

          // Service-specific endpoints
          if ('${{ matrix.service }}' === 'api') {
            let apiRes = http.get(\`\${BASE_URL}/api/CreditTransfer/GetDenomination\`);
            check(apiRes, {
              'API endpoint status is 200': (r) => r.status === 200,
              'API response time < 1000ms': (r) => r.timings.duration < 1000,
            }) || errorRate.add(1);
            
            sleep(1);
          } else if ('${{ matrix.service }}' === 'web') {
            let webRes = http.get(\`\${BASE_URL}/\`);
            check(webRes, {
              'Web page status is 200': (r) => r.status === 200,
              'Web page response time < 2000ms': (r) => r.timings.duration < 2000,
            }) || errorRate.add(1);
            
            sleep(2);
          } else if ('${{ matrix.service }}' === 'wcf') {
            // WCF service testing would go here
            sleep(1);
          }

          sleep(Math.random() * 2); // Random sleep between 0-2 seconds
        }
        EOF

    - name: "üöÄ Execute K6 Load Test"
      run: |
        echo "Starting K6 load test for ${{ matrix.service }}..."
        k6 run --out json=k6-results-${{ matrix.service }}.json k6-test-${{ matrix.service }}.js

    - name: "üìä Process K6 Results"
      run: |
        echo "=== K6 Test Results for ${{ matrix.service }} ===" | tee k6-summary-${{ matrix.service }}.txt
        
        # Extract key metrics from JSON output
        if [ -f "k6-results-${{ matrix.service }}.json" ]; then
          echo "Processing results..." | tee -a k6-summary-${{ matrix.service }}.txt
          
          # Parse last summary line for key metrics
          tail -1 k6-results-${{ matrix.service }}.json | jq -r '
            if .type == "Point" and .metric == "http_req_duration" then
              "Average Response Time: " + (.data.value | tostring) + "ms"
            else empty end
          ' | tee -a k6-summary-${{ matrix.service }}.txt || echo "Response time data not available"
          
          echo "Test completed successfully" | tee -a k6-summary-${{ matrix.service }}.txt
        else
          echo "‚ùå No results file generated" | tee -a k6-summary-${{ matrix.service }}.txt
        fi

    - name: "üìã Upload K6 Results"
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: k6-results-${{ matrix.service }}
        path: |
          k6-results-${{ matrix.service }}.json
          k6-summary-${{ matrix.service }}.txt
          k6-test-${{ matrix.service }}.js
        retention-days: 30

  # Job 3: Artillery Stress Testing
  artillery-stress-tests:
    name: "Artillery Stress Testing"
    runs-on: ubuntu-latest
    needs: prepare-tests
    if: inputs.test_type == 'stress' || inputs.test_type == 'spike' || github.event_name == 'schedule'
    timeout-minutes: 25

    steps:
    - name: "üì• Checkout Code"
      uses: actions/checkout@v4

    - name: "üîß Setup Node.js"
      uses: actions/setup-node@v4
      with:
        node-version: '18'

    - name: "üì¶ Install Artillery"
      run: npm install -g artillery@${{ env.ARTILLERY_VERSION }}

    - name: "üìù Generate Artillery Test Configuration"
      run: |
        CONFIG='${{ needs.prepare-tests.outputs.test-config }}'
        URLS='${{ needs.prepare-tests.outputs.target-urls }}'
        
        DURATION=$(echo $CONFIG | jq -r '.duration' | sed 's/m//')
        USERS=$(echo $CONFIG | jq -r '.users')
        API_URL=$(echo $URLS | jq -r '.api')
        
        cat > artillery-config.yml << EOF
        config:
          target: '$API_URL'
          phases:
            - duration: 120
              arrivalRate: 10
              name: "Warm up"
            - duration: ${DURATION}00
              arrivalRate: $((USERS / 10))
              name: "Stress test"
            - duration: 60
              arrivalRate: 5
              name: "Cool down"
          defaults:
            headers:
              Content-Type: 'application/json'
          plugins:
            metrics-by-endpoint: {}
        scenarios:
          - name: "Health Check Load"
            weight: 50
            flow:
              - get:
                  url: "/health"
          - name: "API Load"
            weight: 50
            flow:
              - get:
                  url: "/api/CreditTransfer/GetDenomination"
              - think: 1
        EOF

    - name: "üöÄ Execute Artillery Stress Test"
      run: |
        echo "Starting Artillery stress test..."
        artillery run artillery-config.yml --output artillery-results.json

    - name: "üìä Generate Artillery Report"
      if: always()
      run: |
        artillery report artillery-results.json --output artillery-report.html || echo "Report generation failed"
        
        echo "=== Artillery Stress Test Summary ===" | tee artillery-summary.txt
        echo "Test completed at: $(date)" | tee -a artillery-summary.txt
        
        if [ -f "artillery-results.json" ]; then
          echo "Results file generated successfully" | tee -a artillery-summary.txt
        fi

    - name: "üìã Upload Artillery Results"
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: artillery-results
        path: |
          artillery-results.json
          artillery-report.html
          artillery-summary.txt
          artillery-config.yml
        retention-days: 30

  # Job 4: .NET Performance Testing
  dotnet-performance-tests:
    name: ".NET Performance Tests"
    runs-on: ubuntu-latest
    needs: prepare-tests
    timeout-minutes: 20

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: credittransfer_perf
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
    - name: "üì• Checkout Code"
      uses: actions/checkout@v4

    - name: "üîß Setup .NET"
      uses: actions/setup-dotnet@v4
      with:
        dotnet-version: ${{ env.DOTNET_VERSION }}

    - name: "üì¶ Cache NuGet Packages"
      uses: actions/cache@v4
      with:
        path: ~/.nuget/packages
        key: ${{ runner.os }}-nuget-${{ hashFiles('**/*.csproj', '**/packages.lock.json') }}
        restore-keys: |
          ${{ runner.os }}-nuget-

    - name: "üîÑ Restore Dependencies"
      run: dotnet restore CreditTransfer.Modern.sln --verbosity minimal

    - name: "üèóÔ∏è Build Solution"
      run: |
        dotnet build CreditTransfer.Modern.sln \
          --configuration Release \
          --no-restore \
          --verbosity minimal

    - name: "üöÄ Run Performance Tests"
      env:
        ConnectionStrings__DefaultConnection: "Host=localhost;Database=credittransfer_perf;Username=postgres;Password=postgres"
      run: |
        dotnet test CreditTransfer.Modern.sln \
          --configuration Release \
          --no-build \
          --verbosity minimal \
          --logger "trx;LogFileName=performance-tests.trx" \
          --logger "GitHubActions;summary.includePassedTests=true;summary.includeSkippedTests=true" \
          --results-directory ./test-results \
          --filter "Category=Performance" \
          --collect:"XPlat Code Coverage" \
          -- RunConfiguration.DisableAppDomain=true

    - name: "üìã Publish Performance Test Results"
      uses: dorny/test-reporter@v1
      if: always()
      with:
        name: "Performance Test Results"
        path: "test-results/*.trx"
        reporter: dotnet-trx

  # Job 5: Memory & Resource Testing
  memory-profiling:
    name: "Memory & Resource Profiling"
    runs-on: ubuntu-latest
    needs: prepare-tests
    if: inputs.test_type == 'volume' || inputs.test_type == 'endurance' || github.event_name == 'schedule'
    timeout-minutes: 30

    steps:
    - name: "üì• Checkout Code"
      uses: actions/checkout@v4

    - name: "üîß Setup .NET"
      uses: actions/setup-dotnet@v4
      with:
        dotnet-version: ${{ env.DOTNET_VERSION }}

    - name: "üìä Install dotMemory Unit"
      run: |
        dotnet tool install --global JetBrains.dotMemoryUnit.Runner

    - name: "üîç Run Memory Profiling"
      run: |
        echo "Running memory profiling tests..."
        # This would run actual memory profiling tests
        echo "Memory profiling completed"

    - name: "üìà Generate Memory Report"
      run: |
        echo "=== Memory Profiling Summary ===" | tee memory-report.txt
        echo "Test completed at: $(date)" | tee -a memory-report.txt
        echo "Memory profiling analysis would be included here" | tee -a memory-report.txt

    - name: "üìã Upload Memory Reports"
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: memory-profiler-results
        path: memory-report.txt
        retention-days: 30

  # Job 6: Performance Summary & Analysis
  performance-summary:
    name: "Performance Summary"
    runs-on: ubuntu-latest
    needs: [prepare-tests, k6-load-tests, artillery-stress-tests, dotnet-performance-tests, memory-profiling]
    if: always()

    steps:
    - name: "üì• Download All Results"
      uses: actions/download-artifact@v4
      with:
        path: ./results

    - name: "üìä Generate Performance Summary"
      run: |
        echo "# üöÄ Performance Test Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## üìã Test Configuration" >> $GITHUB_STEP_SUMMARY
        CONFIG='${{ needs.prepare-tests.outputs.test-config }}'
        echo "- **Test Type**: $(echo $CONFIG | jq -r '.type')" >> $GITHUB_STEP_SUMMARY
        echo "- **Duration**: $(echo $CONFIG | jq -r '.duration')" >> $GITHUB_STEP_SUMMARY
        echo "- **Concurrent Users**: $(echo $CONFIG | jq -r '.users')" >> $GITHUB_STEP_SUMMARY
        echo "- **Environment**: $(echo $CONFIG | jq -r '.environment')" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## üß™ Test Results" >> $GITHUB_STEP_SUMMARY
        echo "| Test Suite | Status | Details |" >> $GITHUB_STEP_SUMMARY
        echo "|------------|--------|---------|" >> $GITHUB_STEP_SUMMARY
        echo "| K6 Load Tests | ${{ needs.k6-load-tests.result == 'success' && '‚úÖ Passed' || (needs.k6-load-tests.result == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ùå Failed') }} | Load testing across all services |" >> $GITHUB_STEP_SUMMARY
        echo "| Artillery Stress | ${{ needs.artillery-stress-tests.result == 'success' && '‚úÖ Passed' || (needs.artillery-stress-tests.result == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ùå Failed') }} | Stress and spike testing |" >> $GITHUB_STEP_SUMMARY
        echo "| .NET Performance | ${{ needs.dotnet-performance-tests.result == 'success' && '‚úÖ Passed' || (needs.dotnet-performance-tests.result == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ùå Failed') }} | Built-in performance tests |" >> $GITHUB_STEP_SUMMARY
        echo "| Memory Profiling | ${{ needs.memory-profiling.result == 'success' && '‚úÖ Passed' || (needs.memory-profiling.result == 'skipped' && '‚è≠Ô∏è Skipped' || '‚ùå Failed') }} | Memory and resource analysis |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Performance Analysis
        echo "## üìà Performance Analysis" >> $GITHUB_STEP_SUMMARY
        echo "### Key Metrics" >> $GITHUB_STEP_SUMMARY
        echo "- **Response Time Target**: < 2000ms (95th percentile)" >> $GITHUB_STEP_SUMMARY
        echo "- **Error Rate Target**: < 5%" >> $GITHUB_STEP_SUMMARY
        echo "- **Throughput Target**: > 10 requests/second" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Detailed results analysis
        if [ -d "./results" ]; then
          echo "### üìä Service Performance Breakdown" >> $GITHUB_STEP_SUMMARY
          for service in api wcf web; do
            if [ -d "./results/k6-results-${service}" ]; then
              echo "- **${service^^} Service**: Results available for analysis" >> $GITHUB_STEP_SUMMARY
            fi
          done
        fi
        
        # Overall status
        ALL_PASSED=true
        if [ "${{ needs.k6-load-tests.result }}" == "failure" ]; then ALL_PASSED=false; fi
        if [ "${{ needs.artillery-stress-tests.result }}" == "failure" ]; then ALL_PASSED=false; fi
        if [ "${{ needs.dotnet-performance-tests.result }}" == "failure" ]; then ALL_PASSED=false; fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        if [ "$ALL_PASSED" = true ]; then
          echo "## üéâ Overall Performance Status: ‚úÖ PASSED" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "All performance tests completed successfully. System meets performance requirements." >> $GITHUB_STEP_SUMMARY
        else
          echo "## ‚ö†Ô∏è Overall Performance Status: ‚ùå PERFORMANCE ISSUES DETECTED" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Performance issues detected. Please review detailed results and optimize bottlenecks." >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## üìã Next Steps" >> $GITHUB_STEP_SUMMARY
        echo "1. Review detailed performance metrics in artifacts" >> $GITHUB_STEP_SUMMARY
        echo "2. Analyze response time distributions and error patterns" >> $GITHUB_STEP_SUMMARY
        echo "3. Identify and optimize performance bottlenecks" >> $GITHUB_STEP_SUMMARY
        echo "4. Consider scaling strategies if needed" >> $GITHUB_STEP_SUMMARY