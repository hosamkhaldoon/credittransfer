# Generated by Cursor - Shared Unit Testing Workflow
# Reusable workflow for executing unit tests with coverage reporting

name: "🧪 Shared Unit Testing"

on:
  workflow_call:
    inputs:
      working-directory:
        description: 'Working directory for the project'
        required: false
        default: './'
        type: string
      solution-file:
        description: 'Solution file to test'
        required: false
        default: '*.sln'
        type: string
      configuration:
        description: 'Build configuration'
        required: false
        default: 'Release'
        type: string
      dotnet-version:
        description: '.NET version to use'
        required: false
        default: '9.0.x'
        type: string
      test-filter:
        description: 'Test filter expression'
        required: false
        default: 'Category!=Integration&Category!=Performance&Category!=Security'
        type: string
      timeout-minutes:
        description: 'Job timeout in minutes'
        required: false
        default: 30
        type: number
      upload-artifacts:
        description: 'Whether to upload test artifacts'
        required: false
        default: true
        type: boolean
      artifact-retention-days:
        description: 'Artifact retention period in days'
        required: false
        default: 30
        type: number
      fail-on-test-failure:
        description: 'Whether to fail the workflow on test failures'
        required: false
        default: false
        type: boolean
      reportgenerator-version:
        description: 'ReportGenerator tool version'
        required: false
        default: '5.3.8'
        type: string
    outputs:
      test-result:
        description: 'Overall test result (success/failure)'
        value: ${{ jobs.unit-tests.outputs.test-result }}
      coverage-percentage:
        description: 'Code coverage percentage'
        value: ${{ jobs.unit-tests.outputs.coverage-percentage }}
      tests-total:
        description: 'Total number of tests'
        value: ${{ jobs.unit-tests.outputs.tests-total }}
      tests-passed:
        description: 'Number of passed tests'
        value: ${{ jobs.unit-tests.outputs.tests-passed }}
      tests-failed:
        description: 'Number of failed tests'
        value: ${{ jobs.unit-tests.outputs.tests-failed }}
      tests-skipped:
        description: 'Number of skipped tests'
        value: ${{ jobs.unit-tests.outputs.tests-skipped }}

jobs:
  unit-tests:
    name: "🧪 Unit Tests"
    runs-on: ubuntu-latest
    timeout-minutes: ${{ inputs.timeout-minutes }}
    
    outputs:
      test-result: ${{ steps.test-execution.outputs.test-result }}
      coverage-percentage: ${{ steps.coverage-analysis.outputs.coverage-percentage }}
      tests-total: ${{ steps.test-execution.outputs.tests-total }}
      tests-passed: ${{ steps.test-execution.outputs.tests-passed }}
      tests-failed: ${{ steps.test-execution.outputs.tests-failed }}
      tests-skipped: ${{ steps.test-execution.outputs.tests-skipped }}
    
    steps:
    - name: "📥 Checkout Code"
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: "🔧 Setup .NET"
      uses: actions/setup-dotnet@v4
      with:
        dotnet-version: ${{ inputs.dotnet-version }}

    - name: "📦 Restore Dependencies"
      working-directory: ${{ inputs.working-directory }}
      run: |
        echo "📦 Restoring NuGet packages..."
        dotnet restore ${{ inputs.solution-file }} --verbosity minimal

    - name: "🔨 Build Solution"
      working-directory: ${{ inputs.working-directory }}
      run: |
        echo "🔨 Building solution..."
        dotnet build ${{ inputs.solution-file }} \
          --configuration ${{ inputs.configuration }} \
          --no-restore \
          --verbosity minimal

    - name: "🧪 Execute Unit Tests"
      id: test-execution
      working-directory: ${{ inputs.working-directory }}
      run: |
        echo "🧪 Running unit tests with coverage..."
        mkdir -p test-results coverage-report
        
        # Generate unique test run ID
        TEST_RUN_ID="unit-tests-$(date +%Y%m%d-%H%M%S)"
        echo "test-run-id=$TEST_RUN_ID" >> $GITHUB_OUTPUT
        
        # Run tests with coverage collection
        TEST_EXIT_CODE=0
        dotnet test ${{ inputs.solution-file }} \
          --configuration ${{ inputs.configuration }} \
          --no-build \
          --logger "trx;LogFileName=$TEST_RUN_ID.trx" \
          --collect:"XPlat Code Coverage" \
          --results-directory ./test-results \
          --filter "${{ inputs.test-filter }}" \
          --verbosity normal || TEST_EXIT_CODE=$?
        
        # Extract test statistics from TRX files
        echo "📊 Analyzing test results..."
        TESTS_TOTAL=0
        TESTS_PASSED=0
        TESTS_FAILED=0
        TESTS_SKIPPED=0
        
        shopt -s globstar nullglob
        for trx_file in test-results/**/*.trx; do
          if [ -f "$trx_file" ]; then
            echo "Processing: $trx_file"
            # Extract counts using basic parsing (more robust than complex XML parsing)
            TOTAL=$(grep -o 'total="[0-9]*"' "$trx_file" | cut -d'"' -f2 || echo "0")
            PASSED=$(grep -o 'passed="[0-9]*"' "$trx_file" | cut -d'"' -f2 || echo "0")
            FAILED=$(grep -o 'failed="[0-9]*"' "$trx_file" | cut -d'"' -f2 || echo "0")
            SKIPPED=$(grep -o 'skipped="[0-9]*"' "$trx_file" | cut -d'"' -f2 || echo "0")
            
            TESTS_TOTAL=$((TESTS_TOTAL + TOTAL))
            TESTS_PASSED=$((TESTS_PASSED + PASSED))
            TESTS_FAILED=$((TESTS_FAILED + FAILED))
            TESTS_SKIPPED=$((TESTS_SKIPPED + SKIPPED))
          fi
        done
        
        # Set outputs
        echo "tests-total=$TESTS_TOTAL" >> $GITHUB_OUTPUT
        echo "tests-passed=$TESTS_PASSED" >> $GITHUB_OUTPUT
        echo "tests-failed=$TESTS_FAILED" >> $GITHUB_OUTPUT
        echo "tests-skipped=$TESTS_SKIPPED" >> $GITHUB_OUTPUT
        
        # Determine overall result
        if [ $TEST_EXIT_CODE -eq 0 ]; then
          echo "test-result=success" >> $GITHUB_OUTPUT
          echo "✅ All tests passed!"
        else
          echo "test-result=failure" >> $GITHUB_OUTPUT
          echo "❌ Some tests failed (exit code: $TEST_EXIT_CODE)"
          if [ "${{ inputs.fail-on-test-failure }}" = "true" ]; then
            echo "🚨 Failing workflow due to test failures"
            exit $TEST_EXIT_CODE
          else
            echo "⚠️ Continuing despite test failures"
          fi
        fi
        
        # Display summary
        echo "📊 Test Summary:"
        echo "  Total: $TESTS_TOTAL"
        echo "  Passed: $TESTS_PASSED"
        echo "  Failed: $TESTS_FAILED"
        echo "  Skipped: $TESTS_SKIPPED"
        
        # Display test results files
        echo "📁 Test result files:"
        find test-results -name "*.trx" -type f || echo "No TRX files found"
        echo "📁 Coverage files:"
        find test-results -name "*coverage*.xml" -type f || echo "No coverage files found"

    - name: "📊 Generate Coverage Report"
      id: coverage-analysis
      if: always()
      working-directory: ${{ inputs.working-directory }}
      run: |
        echo "📊 Generating coverage report..."
        
        # Find coverage files
        shopt -s globstar nullglob
        COVERAGE_FILES=$(echo test-results/**/*coverage*.xml)
        if [ -z "$COVERAGE_FILES" ]; then
          echo "❌ No coverage files found - skipping report generation"
          echo "coverage-percentage=0" >> $GITHUB_OUTPUT
          exit 0
        fi
        
        echo "✅ Found coverage files:"
        echo "$COVERAGE_FILES"
        
        # Install ReportGenerator
        echo "🔧 Installing ReportGenerator..."
        dotnet tool install dotnet-reportgenerator-globaltool \
          --tool-path ../reportgeneratortool \
          --version ${{ inputs.reportgenerator-version }} \
          --ignore-failed-sources
        
        # Generate report with multiple attempts
        REPORT_SUCCESS=false
        
        # Attempt 1: Use pattern-based approach
        echo "📊 Attempting pattern-based report generation..."
        if ../reportgeneratortool/reportgenerator \
          -reports:"test-results/**/*coverage*.xml" \
          -targetdir:coverage-report \
          -reporttypes:HtmlInline_AzurePipelines\;Cobertura\;MarkdownSummaryGithub \
          -verbosity:Info \
          -title:"Unit Test Coverage Report"; then
          REPORT_SUCCESS=true
          echo "✅ Pattern-based generation successful"
        else
          echo "❌ Pattern-based generation failed"
        fi
        
        # Attempt 2: Use explicit file list
        if [ "$REPORT_SUCCESS" = "false" ]; then
          echo "📊 Attempting explicit file list generation..."
          REPORT_FILES=$(echo "$COVERAGE_FILES" | tr '\n' ';' | sed 's/;$//')
          if ../reportgeneratortool/reportgenerator \
            -reports:"$REPORT_FILES" \
            -targetdir:coverage-report \
            -reporttypes:HtmlInline_AzurePipelines\;Cobertura\;MarkdownSummaryGithub \
            -verbosity:Info \
            -title:"Unit Test Coverage Report"; then
            REPORT_SUCCESS=true
            echo "✅ Explicit file list generation successful"
          else
            echo "❌ Both generation attempts failed"
          fi
        fi
        
        # Extract coverage percentage
        COVERAGE_PERCENTAGE=0
        if [ "$REPORT_SUCCESS" = "true" ] && [ -f "coverage-report/Cobertura.xml" ]; then
          # Extract line coverage from Cobertura XML
          COVERAGE_PERCENTAGE=$(grep -o 'line-rate="[0-9.]*"' coverage-report/Cobertura.xml | head -1 | cut -d'"' -f2 | awk '{printf "%.1f", $1*100}' || echo "0")
          echo "📊 Coverage percentage: $COVERAGE_PERCENTAGE%"
        fi
        
        echo "coverage-percentage=$COVERAGE_PERCENTAGE" >> $GITHUB_OUTPUT

    - name: "📋 Publish Test Results"
      uses: dorny/test-reporter@v1
      if: always() && !github.event.pull_request.head.repo.fork
      with:
        name: "Unit Test Results"
        path: "${{ inputs.working-directory }}/test-results/**/*.trx"
        reporter: dotnet-trx
        fail-on-error: false
      continue-on-error: true

    - name: "📊 Upload Test Artifacts"
      uses: actions/upload-artifact@v4
      if: always() && inputs.upload-artifacts
      with:
        name: unit-test-results-${{ steps.test-execution.outputs.test-run-id }}
        path: |
          ${{ inputs.working-directory }}/coverage-report/
          ${{ inputs.working-directory }}/test-results/
        retention-days: ${{ inputs.artifact-retention-days }}

    - name: "📊 Test Summary"
      if: always()
      run: |
        echo "## 🧪 Unit Test Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
        echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
        echo "| 📊 **Total Tests** | ${{ steps.test-execution.outputs.tests-total }} |" >> $GITHUB_STEP_SUMMARY
        echo "| ✅ **Passed** | ${{ steps.test-execution.outputs.tests-passed }} |" >> $GITHUB_STEP_SUMMARY
        echo "| ❌ **Failed** | ${{ steps.test-execution.outputs.tests-failed }} |" >> $GITHUB_STEP_SUMMARY
        echo "| ⏭️ **Skipped** | ${{ steps.test-execution.outputs.tests-skipped }} |" >> $GITHUB_STEP_SUMMARY
        echo "| 📈 **Coverage** | ${{ steps.coverage-analysis.outputs.coverage-percentage }}% |" >> $GITHUB_STEP_SUMMARY
        echo "| 🎯 **Result** | ${{ steps.test-execution.outputs.test-result }} |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ "${{ steps.test-execution.outputs.test-result }}" = "success" ]; then
          echo "🎉 **All unit tests passed successfully!**" >> $GITHUB_STEP_SUMMARY
        else
          echo "⚠️ **Some unit tests failed - check the details above.**" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### 📁 Artifacts" >> $GITHUB_STEP_SUMMARY
        echo "- Coverage Report: Available in workflow artifacts" >> $GITHUB_STEP_SUMMARY
        echo "- Test Results: Available in workflow artifacts" >> $GITHUB_STEP_SUMMARY
        echo "- Filter Used: \`${{ inputs.test-filter }}\`" >> $GITHUB_STEP_SUMMARY